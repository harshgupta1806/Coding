{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Pandas is an open-source library that is built on top of NumPy library. It is a Python package that offers various data structures and operations for manipulating numerical data and time series. It is mainly popular for importing and analyzing data much easier. Pandas is fast and it has high-performance & productivity for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame\n",
    "lst = ['Geeks', 'For', 'Geeks', 'is', 'portal', 'for', 'Geeks']\n",
    "df = pd.DataFrame(lst)\n",
    "print(df)\n",
    "#######################################################\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'],\n",
    "        'Age':[20, 21, 19, 18]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "#######################################################\n",
    "data = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Age':[27, 24, 22, 32],\n",
    "        'Address':['Delhi', 'Kanpur', 'Allahabad', 'Kannauj'],\n",
    "        'Qualification':['Msc', 'MA', 'MCA', 'Phd']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df[['Name', 'Age', 'Address']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas package\n",
    "import pandas as pd\n",
    " \n",
    "# making data frame from csv file\n",
    "data = pd.read_csv(\"nba.csv\", index_col =\"Name\")\n",
    " \n",
    "# retrieving row by loc method\n",
    "# first = data.loc[\"Avery Bradley\"]\n",
    "# second = data.loc[\"R.J. Hunter\"]\n",
    "# third = data.loc['Derrick Williams']\n",
    " \n",
    "# print(first, \"\\n\\n\\n\", third)\n",
    "\n",
    "# age1=data.loc[20.0]\n",
    "# print(age1)\n",
    "\n",
    "# print(data.index)\n",
    "\n",
    "# print(data[\"Age\"])\n",
    "\n",
    "# Explanation:\n",
    "# The column named \"Name\" in the CSV file will be used as the index for the DataFrame instead of the default integer index (0, 1, 2, ...).\n",
    "# This means that instead of the rows being identified by default numbers, they will be identified by the values in the \"Name\" column.\n",
    "\n",
    "# The index_col parameter in pandas.read_csv() is used to specify which column in the CSV file should be used as the row labels (index) of the resulting DataFrame.\n",
    "\n",
    "\n",
    "print(data.iloc[[1,2,3,4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'First Score':[100, 90, np.nan, 95],\n",
    "        'Second Score': [30, 45, 56, np.nan],\n",
    "        'Third Score':[np.nan, 40, 80, 98]}\n",
    " \n",
    "# creating a dataframe from list\n",
    "df = pd.DataFrame(dict)\n",
    " \n",
    "# using isnull() function  \n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, np.nan, 6]})\n",
    "\n",
    "# Fill with a specific value\n",
    "df.fillna(0)\n",
    "\n",
    "# Fill with the column mean\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "\n",
    "# Forward-fill (use the previous value to fill)\n",
    "df.fillna(method='ffill')\n",
    "\n",
    "# Backward-fill (use the next value to fill)\n",
    "df.fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method=None)\n",
    "\n",
    "df = pd.DataFrame({'A': [1, -1, 3], 'B': [-1, 5, -1]})\n",
    "\n",
    "# Replace all -1 values with 0\n",
    "df.replace(-1, 0)\n",
    "\n",
    "# Replace multiple values\n",
    "# df.replace([-1, 3], 0)\n",
    "\n",
    "# Replace with regex (e.g., replace any digit with 'X')\n",
    "# df.replace(to_replace=r'\\d', value='X', regex=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.interpolate(method='linear', axis=0, inplace=False, limit=None, limit_direction='forward', limit_area=None, downcast=None)\n",
    "\n",
    "df = pd.DataFrame({'A': [1, np.nan, 3, np.nan, 5]})\n",
    "\n",
    "# Linear interpolation (default)\n",
    "df.interpolate()\n",
    "\n",
    "# Polynomial interpolation (quadratic)\n",
    "df.interpolate(method='polynomial', order=2)\n",
    "\n",
    "# Interpolation along rows (axis=1)\n",
    "df.interpolate(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    " \n",
    "# importing numpy as np\n",
    "import numpy as np\n",
    " \n",
    "# dictionary of lists\n",
    "dict = {'First Score':[100, 90, np.nan, 95],\n",
    "        'Second Score': [30, np.nan, 45, 56],\n",
    "        'Third Score':[52, 40, 80, 98],\n",
    "        'Fourth Score':[np.nan, np.nan, np.nan, 65]}\n",
    " \n",
    "# creating a dataframe from dictionary\n",
    "df = pd.DataFrame(dict)\n",
    "df\n",
    "# using dropna() function  \n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. iteritems()\n",
    "# Purpose: Used to iterate over columns of a DataFrame as (column_name, column_data) pairs.\n",
    "# Iterates Over: Columns.\n",
    "# When to Use: When you need to work with or inspect the data column by column.\n",
    "\n",
    "\n",
    "# . iterrows()\n",
    "# Purpose: Used to iterate over rows of a DataFrame as (index, Series) pairs.\n",
    "# Iterates Over: Rows.\n",
    "# When to Use: When you need to access row-wise data but do not need maximum performance.\n",
    "\n",
    "\n",
    "dict = {'name':[\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "        'degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "        'score':[90, 40, 80, 98]}\n",
    " \n",
    "# creating a dataframe from a dictionary \n",
    "df = pd.DataFrame(dict)\n",
    " \n",
    "# iterating over rows using iterrows() function \n",
    "for i, j in df.iterrows():\n",
    "    print(i, j)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "# itertuples()\n",
    "# Purpose: Used to iterate over rows of a DataFrame as namedtuples.\n",
    "# Iterates Over: Rows (like iterrows()), but as namedtuples.\n",
    "# When to Use: When you need better performance while iterating through rows.\n",
    "# Iterating over rows as namedtuples\n",
    "for row in df.itertuples():\n",
    "    print(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index()\tMethod returns index (row labels) of the DataFrame\n",
    "# insert()\tMethod inserts a column into a DataFrame\n",
    "# add()\tMethod returns addition of dataframe and other, element-wise (binary operator add)\n",
    "# sub()\tMethod returns subtraction of dataframe and other, element-wise (binary operator sub)\n",
    "# mul()\tMethod returns multiplication of dataframe and other, element-wise (binary operator mul)\n",
    "# div()\tMethod returns floating division of dataframe and other, element-wise (binary operator truediv)\n",
    "# unique()\tMethod extracts the unique values in the dataframe\n",
    "# nunique()\tMethod returns count of the unique values in the dataframe\n",
    "# value_counts()\tMethod counts the number of times each unique value occurs within the Series\n",
    "# columns()\tMethod returns the column labels of the DataFrame\n",
    "# axes()\tMethod returns a list representing the axes of the DataFrame\n",
    "# isnull()\tMethod creates a Boolean Series for extracting rows with null values\n",
    "# notnull()\tMethod creates a Boolean Series for extracting rows with non-null values\n",
    "# between()\tMethod extracts rows where a column value falls in between a predefined range\n",
    "# isin()\tMethod extracts rows from a DataFrame where a column value exists in a predefined collection\n",
    "# dtypes()\tMethod returns a Series with the data type of each column. The result’s index is the original DataFrame’s columns\n",
    "# astype()\tMethod converts the data types in a Series\n",
    "# values()\tMethod returns a Numpy representation of the DataFrame i.e. only the values in the DataFrame will be returned, the axes labels will be removed\n",
    "# sort_values()- Set1, Set2\tMethod sorts a data frame in Ascending or Descending order of passed Column\n",
    "# sort_index()\tMethod sorts the values in a DataFrame based on their index positions or labels instead of their values but sometimes a data frame is made out of two or more data frames and hence later index can be changed using this method\n",
    "# loc[]\tMethod retrieves rows based on index label\n",
    "# iloc[]\tMethod retrieves rows based on index position\n",
    "# ix[]\tMethod retrieves DataFrame rows based on either index label or index position. This method combines the best features of the .loc[] and .iloc[] methods\n",
    "# rename()\tMethod is called on a DataFrame to change the names of the index labels or column names\n",
    "# columns()\tMethod is an alternative attribute to change the coloumn name\n",
    "# drop()\tMethod is used to delete rows or columns from a DataFrame\n",
    "# pop()\tMethod is used to delete rows or columns from a DataFrame\n",
    "# sample()\tMethod pulls out a random sample of rows or columns from a DataFrame\n",
    "# nsmallest()\tMethod pulls out the rows with the smallest values in a column\n",
    "# nlargest()\tMethod pulls out the rows with the largest values in a column\n",
    "# shape()\tMethod returns a tuple representing the dimensionality of the DataFrame\n",
    "# ndim()\tMethod returns an ‘int’ representing the number of axes / array dimensions.\n",
    "# Returns 1 if Series, otherwise returns 2 if DataFrame\n",
    "# dropna()\tMethod allows the user to analyze and drop Rows/Columns with Null values in different ways\n",
    "# fillna()\tMethod manages and let the user replace NaN values with some value of their own\n",
    "# rank()\tValues in a Series can be ranked in order with this method\n",
    "# query()\tMethod is an alternate string-based syntax for extracting a subset from a DataFrame\n",
    "# copy()\tMethod creates an independent copy of a pandas object\n",
    "# duplicated()\tMethod creates a Boolean Series and uses it to extract rows that have duplicate values\n",
    "# drop_duplicates()\tMethod is an alternative option to identifying duplicate rows and removing them through filtering\n",
    "# set_index()\tMethod sets the DataFrame index (row labels) using one or more existing columns\n",
    "# reset_index()\tMethod resets index of a Data Frame. This method sets a list of integer ranging from 0 to length of data as index\n",
    "# where()\tMethod is used to check a Data Frame for one or more condition and return the result accordingly. By default, the rows not satisfying the condition are filled with NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# dictionary of lists\n",
    "dict = {'name':[\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "\t\t'degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "\t\t'score':[90, 40, 80, 98]}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Pandas Series\n",
    "Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4]\n",
    "ser = pd.Series(data)\n",
    "print(ser)\n",
    "\n",
    "data = np.array(['g','e','e','k','s','f', 'o','r','g','e','e','k','s'])\n",
    "ser = pd.Series(data)\n",
    "print(ser[2:7:2])\n",
    "\n",
    "ser = pd.Series(data,index=[10,11,12,13,14,15,16,17,18,19,20,21,22])\n",
    "print(ser[10])\n",
    "\n",
    "df = pd.read_csv(\"nba.csv\")  \n",
    "ser = pd.Series(df['Name']) \n",
    "data = ser.head(10)\n",
    "# data[3:6] # 6 excluded\n",
    "# data.loc[3:6] # # 6 included\n",
    "data.iloc[3:6] # 6 excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas module  \n",
    "import pandas as pd  \n",
    " \n",
    "# creating a series\n",
    "data = pd.Series([5, 2, 3,7], index=['a', 'b', 'c', 'f'])\n",
    " \n",
    "# creating a series\n",
    "data1 = pd.Series([1, 6, 4, np.nan], index=['a', 'b', 'd', 'f'])\n",
    " \n",
    "print(data, \"\\n\\n\", data1)\n",
    "\n",
    "# adding two series using\n",
    "# .add\n",
    "data.add(data1, fill_value=0) # nan consodered as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program using astype\n",
    "# to convert a datatype of series\n",
    " \n",
    "# importing pandas module  \n",
    "import pandas as pd \n",
    "   \n",
    "# reading csv file from url  \n",
    "data = pd.read_csv(\"nba.csv\") \n",
    "    \n",
    "# dropping null value columns to avoid errors \n",
    "data.dropna(inplace = True) \n",
    "   \n",
    "# storing dtype before converting \n",
    "before = data.dtypes \n",
    "   \n",
    "# converting dtypes using astype \n",
    "data[\"Salary\"]= data[\"Salary\"].astype(int) \n",
    "data[\"Number\"]= data[\"Number\"].astype(str) \n",
    "   \n",
    "# storing dtype after converting \n",
    "after = data.dtypes \n",
    "   \n",
    "# printing to compare \n",
    "print(\"BEFORE CONVERSION\\n\", before, \"\\n\") \n",
    "print(\"AFTER CONVERSION\\n\", after, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program converting\n",
    "# a series into list\n",
    " \n",
    "# importing pandas module  \n",
    "import pandas as pd  \n",
    "   \n",
    "# importing regex module \n",
    "import re \n",
    "     \n",
    "# making data frame  \n",
    "data = pd.read_csv(\"nba.csv\")  \n",
    "     \n",
    "# removing null values to avoid errors  \n",
    "data.dropna(inplace = True)  \n",
    "   \n",
    "# storing dtype before operation \n",
    "dtype_before = type(data[\"Salary\"]) \n",
    "   \n",
    "# converting to list \n",
    "salary_list = data[\"Salary\"].tolist() \n",
    "   \n",
    "# storing dtype after operation \n",
    "dtype_after = type(salary_list) \n",
    "   \n",
    "# printing dtype \n",
    "print(\"Data type before converting = {}\\nData type after converting = {}\"\n",
    "      .format(dtype_before, dtype_after)) \n",
    "   \n",
    "# displaying list \n",
    "salary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary operation methods on series:\n",
    "\n",
    "# FUNCTION\tDESCRIPTION\n",
    "# add()\tMethod is used to add series or list like objects with same length to the caller series\n",
    "# sub()\tMethod is used to subtract series or list like objects with same length from the caller series\n",
    "# mul()\tMethod is used to multiply series or list like objects with same length with the caller series\n",
    "# div()\tMethod is used to divide series or list like objects with same length by the caller series\n",
    "# sum()\tReturns the sum of the values for the requested axis\n",
    "# prod()\tReturns the product of the values for the requested axis\n",
    "# mean()\tReturns the mean of the values for the requested axis\n",
    "# pow()\tMethod is used to put each element of passed series as exponential power of caller series and returned the results\n",
    "# abs()\tMethod is used to get the absolute numeric value of each element in Series/DataFrame\n",
    "# cov()\tMethod is used to find covariance of two series\n",
    " \n",
    "# Pandas series method:\n",
    "\n",
    "# FUNCTION\tDESCRIPTION\n",
    "# Series()\tA pandas Series can be created with the Series() constructor method. This constructor method accepts a variety of inputs\n",
    "# combine_first()\tMethod is used to combine two series into one\n",
    "# count()\tReturns number of non-NA/null observations in the Series\n",
    "# size()\tReturns the number of elements in the underlying data\n",
    "# name()\tMethod allows to give a name to a Series object, i.e. to the column\n",
    "# is_unique()\tMethod returns boolean if values in the object are unique\n",
    "# idxmax()\tMethod to extract the index positions of the highest values in a Series\n",
    "# idxmin()\tMethod to extract the index positions of the lowest values in a Series\n",
    "# sort_values()\tMethod is called on a Series to sort the values in ascending or descending order\n",
    "# sort_index()\tMethod is called on a pandas Series to sort it by the index instead of its values\n",
    "# head()\tMethod is used to return a specified number of rows from the beginning of a Series. The method returns a brand new Series\n",
    "# tail()\tMethod is used to return a specified number of rows from the end of a Series. The method returns a brand new Series\n",
    "# le()\tUsed to compare every element of Caller series with passed series.It returns True for every element which is Less than or Equal to the element in passed series\n",
    "# ne()\tUsed to compare every element of Caller series with passed series. It returns True for every element which is Not Equal to the element in passed series\n",
    "# ge()\tUsed to compare every element of Caller series with passed series. It returns True for every element which is Greater than or Equal to the element in passed series\n",
    "# eq()\tUsed to compare every element of Caller series with passed series. It returns True for every element which is Equal to the element in passed series\n",
    "# gt()\tUsed to compare two series and return Boolean value for every respective element\n",
    "# lt()\tUsed to compare two series and return Boolean value for every respective element\n",
    "# clip()\tUsed to clip value below and above to passed Least and Max value\n",
    "# clip_lower()\tUsed to clip values below a passed least value\n",
    "# clip_upper()\tUsed to clip values above a passed maximum value\n",
    "# astype()\tMethod is used to change data type of a series\n",
    "# tolist()\tMethod is used to convert a series to list\n",
    "# get()\tMethod is called on a Series to extract values from a Series. This is alternative syntax to the traditional bracket syntax\n",
    "# unique()\tPandas unique() is used to see the unique values in a particular column\n",
    "# nunique()\tPandas nunique() is used to get a count of unique values\n",
    "# value_counts()\tMethod to count the number of the times each unique value occurs in a Series\n",
    "# factorize()\tMethod helps to get the numeric representation of an array by identifying distinct values\n",
    "# map()\tMethod to tie together the values from one object to another\n",
    "# between()\tPandas between() method is used on series to check which values lie between first and second argument\n",
    "# apply()\tMethod is called and feeded a Python function as an argument to use the function on every Series value. This method is helpful for executing custom operations that are not included in pandas or numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series with numpy linspace()\n",
    "ser1 = pd.Series(np.linspace(3, 33, 3))\n",
    "print(ser1)\n",
    "\n",
    "# series with numpy linspace()\n",
    "ser2 = pd.Series(np.linspace(1, 100, 10))\n",
    "print(\"\\n\"\t , ser2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Data\n",
    "\n",
    "Syntax: Dataframe.head(n=5)\n",
    "\n",
    "Parameters: \n",
    "    \n",
    "    n: integer value, number of rows to be returned\n",
    "    \n",
    "    Return type: Dataframe with top n rows \n",
    "\n",
    "    n (5 by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\") \n",
    "data_top = data.head(n=7)\n",
    "data_bottom = data.tail(n=7)\n",
    "# data_top\n",
    "data_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrame describe()\n",
    "Pandas describe() is used to view some basic statistical details like percentile, mean, std, etc. of a data frame or a series of numeric values. When this method is applied to a series of strings, it returns a different output which is shown in the examples below.\n",
    "\n",
    "Syntax: DataFrame.describe(percentiles=None, include=None, exclude=None) \n",
    "\n",
    "\n",
    "Parameters: \n",
    "\n",
    "\n",
    "percentile: list like data type of numbers between 0-1 to return the respective percentile \n",
    "\n",
    "include: List of data types to be included while describing dataframe. Default is None \n",
    "\n",
    "exclude: List of data types to be Excluded while describing dataframe. Default is None \n",
    "\n",
    "Return type: Statistical summary of data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nba.csv')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('nba.csv')\n",
    "\n",
    "# removing null values to avoid errors\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# percentile list\n",
    "perc = [.20, .40, .60, .80]\n",
    "\n",
    "# list of dtypes to include\n",
    "include = ['object', 'float', 'int']\n",
    "\n",
    "# calling describe method\n",
    "desc = data.describe(percentiles=perc, include=include)\n",
    "\n",
    "# display\n",
    "desc\n",
    "\n",
    "# percentiles\n",
    "# Specifies custom percentiles (quartiles) for the summary statistics.\n",
    "# By default, describe() computes the 25th, 50th, and 75th percentiles. With the percentiles parameter, you can include custom values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\")\n",
    "data.dropna(inplace=True)\n",
    "desc = data[\"Name\"].describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax: Dataframe.to_numpy(dtype = None, copy = False) \n",
    "\n",
    "\n",
    "Parameters: \n",
    "\n",
    "\n",
    "dtype: Data type which we are passing like str. \n",
    "copy: [bool, default False] Ensures that the returned value is a not a view on another array.\n",
    "\n",
    "Returns: numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9],\n",
    "     [10, 11, 12]],\n",
    "    columns=['a', 'b', 'c'])\n",
    " \n",
    "print(df)\n",
    "# convert dataframe to numpy array\n",
    "arr = df.to_numpy()\n",
    "print('\\nNumpy Array\\n----------\\n', arr)\n",
    "print(type(arr))\n",
    "\n",
    "\n",
    "arr = df[['a','b']].to_numpy()\n",
    "print('\\nNumpy Array\\n----------\\n', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\")\n",
    "# data.dropna(inplace=True)\n",
    "df = pd.DataFrame(data['Weight'].head())\n",
    "print(df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\")  \n",
    "     \n",
    "data.dropna(inplace = True) \n",
    "  \n",
    "# creating series form weight column \n",
    "gfg = pd.Series(data['Weight'].head()) \n",
    "  \n",
    "# using to_numpy() function \n",
    "print(type(gfg.to_numpy()))\n",
    "print(gfg.to_numpy(dtype ='float32')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Series.as_matrix() function is used to convert the given series or dataframe object to Numpy-array representation.\n",
    "\n",
    "Syntax: Series.as_matrix(columns=None)\n",
    "\n",
    "\n",
    "Parameter : \n",
    "\n",
    "columns :  If None, return all columns, otherwise, returns specified columns.\n",
    "\n",
    "\n",
    "Returns : values : ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pd.Series(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio']) \n",
    "  \n",
    "# Create the Index \n",
    "index_ = ['City 1', 'City 2', 'City 3', 'City 4', 'City 5']  \n",
    "  \n",
    "# set the index \n",
    "sr.index = index_ \n",
    "  \n",
    "# Print the series \n",
    "print(sr) \n",
    "\n",
    "# result = sr.as_matrix() \n",
    "  \n",
    "# # Print the result \n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Series \n",
    "sr = pd.Series([11, 21, 8, 18, 65, 18, 32, 10, 5, 32, None]) \n",
    "  \n",
    "# Create the Index \n",
    "# apply yearly frequency \n",
    "index_ = pd.date_range('2010-10-09 08:45', periods = 11, freq ='Y') \n",
    "  \n",
    "# set the index \n",
    "sr.index = index_ \n",
    "  \n",
    "# Print the series \n",
    "print(sr) \n",
    "\n",
    "\n",
    "# return numpy array representation \n",
    "# result = sr.as_matrix() \n",
    "  \n",
    "# # Print the result \n",
    "# print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Define a dictionary containing employee data\n",
    "data = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "\t\t'Age':[27, 24, 22, 32],\n",
    "\t\t'Address':['Delhi', 'Kanpur', 'Allahabad', 'Kannauj'],\n",
    "\t\t'Qualification':['Msc', 'MA', 'MCA', 'Phd']}\n",
    "\n",
    "# Convert the dictionary into DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# select two columns\n",
    "print(df[['Name', 'Qualification']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# making data frame from csv file\n",
    "data = pd.read_csv(\"nba.csv\", index_col =\"Name\" )\n",
    "\n",
    "# dropping passed columns\n",
    "data.drop([\"Team\", \"Weight\"], axis = 1, inplace = True)\n",
    "\n",
    "# display\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\", index_col =\"Name\")\n",
    " \n",
    "# retrieving row by loc method\n",
    "first = data.loc[\"Avery Bradley\"]\n",
    "second = data.loc[\"R.J. Hunter\"]\n",
    " \n",
    " \n",
    "print(first, \"\\n\\n\\n\", second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\", index_col =\"Name\" )\n",
    "\n",
    "data.drop([\"Jae Crowder\", \"John Holland\", \"R.J. Hunter\",\n",
    "                            \"R.J. Hunter\"], inplace = True)\n",
    " \n",
    "# display\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# making data frame from csv file\n",
    "data = pd.read_csv('nba.csv')\n",
    "\n",
    "# retrieving rows by loc method\n",
    "row1 = data.iloc[[4, 5, 6, 7]]\n",
    "\n",
    "# retrieving rows by loc method\n",
    "row2 = data.iloc[4:8]\n",
    "\n",
    "# comparing values\n",
    "# row1 == row2\n",
    "\n",
    "print(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'name':[\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "        'degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "        'score':[90, 40, 80, 98]}\n",
    "  \n",
    "df = pd.DataFrame(dict, index = [True, False, True, False])\n",
    "  \n",
    "# print(df)\n",
    "print(df.loc[True]['name'])\n",
    "# print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba1.1.csv\")\n",
    "  \n",
    "df = pd.DataFrame(data, index = [0, 1, 2, 3, 4, 5, 6,\n",
    "                                 7, 8, 9, 10, 11, 12])\n",
    " \n",
    "  \n",
    "print(df[[True, False, True, False, True,\n",
    "    False, True, False, True, False,\n",
    "                True, False, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'name':[\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "        'degree': [\"BCA\", \"BCA\", \"M.Tech\", \"BCA\"],\n",
    "        'score':[90, 40, 80, 98]}\n",
    " \n",
    "# creating a dataframe \n",
    "df = pd.DataFrame(dict)\n",
    "  \n",
    "# using a comparison operator for filtering of data\n",
    "print(df['degree'] == 'BCA')\n",
    "\n",
    "\n",
    "mask = df.index == 0\n",
    "print(df[mask])\n",
    "\n",
    "mask = df.index > 7\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Pandas', 'Geeks', 'for', 'Geeks'],\n",
    "        'Height': [1, 2, 3, 4],\n",
    "        'Qualification': ['A', 'B', 'C', 'D']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# using a list\n",
    "# address = ['NewYork', 'Chicago', 'Boston', 'Miami']\n",
    "# df['Address'] = address\n",
    "\n",
    "# By using DataFrame.assign() method\n",
    "# df2 = df.assign(address = ['NewYork', 'Chicago', 'Boston', 'Miami'])\n",
    "# print(df2)\n",
    "\n",
    "\n",
    "# By using Dictionary\n",
    "# address dictionary with names as keys & addresses as values\n",
    "# address = {'Pandas': 'NewYork', 'Geeks': 'Chicago', \n",
    "        #    'for': 'Boston', 'Geeks_2': 'Miami'}\n",
    "# Add the 'Address' column by mapping the 'Name' column\n",
    "# to the address dictionary\n",
    "# df['Address'] = df['Name'].map(address)\n",
    "# print(df)\n",
    "\n",
    "# new_columns = {'Age': [21, 22, 23, 24], \n",
    "#                'City': ['NY', 'LA', 'SF', 'DC']}\n",
    "# df = df.assign(**new_columns)\n",
    "# print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.insert(loc, column, value, allow_duplicates=False)\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Insert a new column 'C' at position 1\n",
    "# df.insert(1, 'C', [10, 20, 30])\n",
    "# print(df)\n",
    "\n",
    "# Insert column 'A' again with duplicate name\n",
    "df.insert(0, 'A', [7, 8, 9], allow_duplicates=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dictionary containing Students data\n",
    "data = {'Name': ['Pandas', 'Geeks', 'for', 'Geeks'],\n",
    "        'Height': [1, 2, 3, 4],\n",
    "        'Qualification': ['A', 'B', 'C', 'D']}\n",
    "\n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Using .loc[] to add a \"Category\" column \n",
    "# based on height condition\n",
    "df.loc[df['Height'] >= 3, 'Category'] = 'Tall'\n",
    "df.loc[df['Height'] < 3, 'Category'] = 'Short'\n",
    "\n",
    "# Observe the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python | Delete rows/columns from DataFrame using Pandas.drop()\n",
    "\n",
    "Syntax: DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors=’raise’)\n",
    "\n",
    "\n",
    "Parameters: \n",
    "\n",
    "\n",
    "labels: String or list of strings referring row or column name. \n",
    "\n",
    "axis: int or string value, 0 ‘index’ for Rows and 1 ‘columns’ for Columns. \n",
    "\n",
    "index or columns: Single label or list. index or columns are an alternative to axis and cannot be used together. \n",
    "\n",
    "level: Used to specify level in case data frame is having multiple level index. \n",
    "\n",
    "inplace: Makes changes in original Data Frame if True. \n",
    "\n",
    "errors: Ignores error if any value from the list doesn’t exists and drops rest of the values when errors = ‘ignore’   \n",
    "\n",
    "Return type: Dataframe with dropped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# making data frame from csv file\n",
    "data = pd.read_csv(\"nba.csv\", index_col=\"Name\")\n",
    "print(data.head(5))\n",
    "\n",
    "# axis =0 default\n",
    "# data.drop([\"Avery Bradley\", \"John Holland\", \"R.J. Hunter\"], inplace = True)\n",
    " \n",
    "data.drop([\"Team\", \"Weight\"], axis = 1, inplace = True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Weight':[45, 88, 56, 15, 71], \n",
    "                   'Name':['Sam', 'Andrea', 'Alex', 'Robin', 'Kia'], \n",
    "                   'Age':[14, 25, 55, 8, 21]}) \n",
    "  \n",
    "# Create the index \n",
    "index_ = pd.date_range('2010-10-09 08:45', periods = 5, freq ='H') \n",
    "  \n",
    "# Set the index \n",
    "df.index = index_ \n",
    "  \n",
    "# Print the DataFrame \n",
    "print(df)\n",
    "\n",
    "# Now we will use DataFrame.truncate() function to truncate the entries before ‘2010-10-09 09:45:00’ and after ‘2010-10-09 11:45:00’ in the given dataframe.\n",
    "result = df.truncate(before = '2010-10-09 09:45:00', after = '2010-10-09 11:45:00') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\":[12, 4, 5, None, 1],  \n",
    "                   \"B\":[7, 2, 54, 3, None],  \n",
    "                   \"C\":[20, 16, 11, 3, 8],  \n",
    "                   \"D\":[14, 3, None, 2, 6]})  \n",
    "  \n",
    "# Create the index \n",
    "index_ = ['Row_1', 'Row_2', 'Row_3', 'Row_4', 'Row_5'] \n",
    "  \n",
    "# Set the index \n",
    "df.index = index_ \n",
    "  \n",
    "# Print the DataFrame \n",
    "print(df) \n",
    "\n",
    "result = df.truncate(before = 'Row_3', after = 'Row_4') \n",
    "  \n",
    "# Print the result \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Creating the Series\n",
    "sr = pd.Series(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio', 'Moscow'])\n",
    "\n",
    "# Create the Datetime Index\n",
    "didx = pd.date_range(start='2014-08-01 10:00', freq='W', \n",
    "                     periods=6, tz='Europe/Berlin') \n",
    "\n",
    "# Set the index\n",
    "sr.index = didx\n",
    "\n",
    "# Print the series\n",
    "print(sr,end='\\n\\n')\n",
    "\n",
    "# Truncate the Series to start after a specific time\n",
    "sr_truncated = sr.truncate(before='2014-08-17 10:00:00+02:00')\n",
    "print(sr_truncated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Creating the Series\n",
    "sr = pd.Series([19.5, 16.8, 22.78, 20.124, 18.1002])\n",
    "\n",
    "# Print the series\n",
    "sr=sr.truncate(before = 1, after = 3)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrame :\n",
    "\n",
    "isnull()\n",
    "notnull()\n",
    "dropna()\n",
    "fillna()\n",
    "replace()\n",
    "interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'First Score':[100, 90, np.nan, 95],\n",
    "        'Second Score': [30, 45, 56, np.nan],\n",
    "        'Third Score':[np.nan, 40, 80, 98]}\n",
    "df = pd.DataFrame(dict).isnull()\n",
    "df1 = pd.DataFrame(dict).notnull()\n",
    "print(df,df1,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"employees.csv\") \n",
    "# Creating a boolean series: True for NaN values\n",
    "# bool_series = pd.isnull(data[\"Gender\"]) \n",
    "# Filtering data and displaying rows where \"Gender\" is NaN\n",
    "nan_gender_data = data[pd.isnull(data[\"Gender\"])]\n",
    "print(nan_gender_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python | Pandas Dataframe.sort_values() | Set-1\n",
    "\n",
    "Syntax: DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)\n",
    "\n",
    "\n",
    "Note: Every parameter has some default values except the ‘by’ parameter.\n",
    "\n",
    "\n",
    "Parameters: \n",
    "\n",
    "\n",
    "by: Single/List of column names to sort Data Frame by. \n",
    "\n",
    "axis: 0 or ‘index’ for rows and 1 or ‘columns’ for Column. \n",
    "\n",
    "ascending: Boolean value which sorts Data frame in ascending order if True. \n",
    "\n",
    "inplace: Boolean value. Makes the changes in passed data frame itself if True. \n",
    "\n",
    "kind: String which can have three inputs(‘quicksort’, ‘mergesort’ or ‘heapsort’) of algorithm used to sort data frame. \n",
    "\n",
    "na_position: Takes two string input ‘last’ or ‘first’ to set position of Null values. Default is ‘last’.\n",
    "\n",
    "Return Type: \n",
    "\n",
    "\n",
    "Returns a sorted Data Frame with Same dimensions as of the function caller DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nba.csv\")\n",
    "data.sort_values(\"Name\", axis=0, ascending=True,\n",
    "                 inplace=True, na_position='last')\n",
    "data.sort_values(\"Salary\", axis=0, ascending=False,\n",
    "                 inplace=True, na_position='last')\n",
    "# display\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python | Pandas Dataframe.sort_values() | Set-2\n",
    "\n",
    "DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Kelly Oubre Jr.</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-7</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1920240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5694674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Otto Porter Jr.</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>4662960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Jarell Eddie</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>8.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6-7</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>561716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-4</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>15851950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Tiago Splitter</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>11.0</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9756250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Thabo Sefolosha</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>25.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6-7</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Kyle Korver</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>26.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6-7</td>\n",
       "      <td>212.0</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>5746479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Kirk Hinrich</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6-4</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>2854940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                Team  Number Position   Age Height  \\\n",
       "377  Kelly Oubre Jr.  Washington Wizards    12.0       SF  20.0    6-7   \n",
       "369     Bradley Beal  Washington Wizards     3.0       SG  22.0    6-5   \n",
       "378  Otto Porter Jr.  Washington Wizards    22.0       SF  23.0    6-8   \n",
       "371     Jarell Eddie  Washington Wizards     8.0       SG  24.0    6-7   \n",
       "382        John Wall  Washington Wizards     2.0       PG  25.0    6-4   \n",
       "..               ...                 ...     ...      ...   ...    ...   \n",
       "321   Tiago Splitter       Atlanta Hawks    11.0        C  31.0   6-11   \n",
       "320  Thabo Sefolosha       Atlanta Hawks    25.0       SF  32.0    6-7   \n",
       "314      Kyle Korver       Atlanta Hawks    26.0       SG  35.0    6-7   \n",
       "311     Kirk Hinrich       Atlanta Hawks    12.0       SG  35.0    6-4   \n",
       "457              NaN                 NaN     NaN      NaN   NaN    NaN   \n",
       "\n",
       "     Weight        College      Salary  \n",
       "377   205.0         Kansas   1920240.0  \n",
       "369   207.0        Florida   5694674.0  \n",
       "378   198.0     Georgetown   4662960.0  \n",
       "371   218.0  Virginia Tech    561716.0  \n",
       "382   195.0       Kentucky  15851950.0  \n",
       "..      ...            ...         ...  \n",
       "321   245.0            NaN   9756250.0  \n",
       "320   220.0            NaN   4000000.0  \n",
       "314   212.0      Creighton   5746479.0  \n",
       "311   190.0         Kansas   2854940.0  \n",
       "457     NaN            NaN         NaN  \n",
       "\n",
       "[458 rows x 9 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"nba.csv\") \n",
    "  \n",
    "#sorting data frame by Team and then By names \n",
    "data.sort_values([\"Team\", \"Name\"], axis=0, \n",
    "                 ascending=[True,False], inplace=True) \n",
    "  \n",
    "#display \n",
    "\n",
    "data.sort_values([\"Team\", \"Age\", \"Height\"], axis=0, \n",
    "                 ascending=[False,True,False], \n",
    "inplace=True) \n",
    "data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
